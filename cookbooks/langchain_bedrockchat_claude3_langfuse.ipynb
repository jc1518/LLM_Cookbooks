{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a51d085-53ff-4615-8763-d5b2cdd30364",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip --quiet\n",
    "!pip install pillow matplotlib --quiet\n",
    "!pip install boto3 --quiet\n",
    "!pip install langchain --quiet\n",
    "!pip install langfuse --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ab7348d-f031-44b4-89de-82b3b8c3a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "\n",
    "boto_session = boto3.Session(profile_name=\"sandbox\", region_name=\"us-west-2\")\n",
    "bedrock_runtime=boto_session.client(service_name=\"bedrock-runtime\")\n",
    "\n",
    "#model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "model_kwargs =  { \n",
    "    \"max_tokens\": 512,\n",
    "    # \"temperature\": 0.0,\n",
    "    # \"top_k\": 250,\n",
    "    # \"top_p\": 1,\n",
    "}\n",
    "\n",
    "model = BedrockChat(\n",
    "    client=bedrock_runtime,\n",
    "    model_id=model_id,\n",
    "    model_kwargs=model_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d140745b-dfbc-4146-8afb-fa01365f055a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n",
      " ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\"\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = getpass.getpass()\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d15ff985-5d51-40a7-a95b-41fd1012f673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "langfuse_handler = CallbackHandler(session_id=model_id)\n",
    "langfuse_handler.auth_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dbfa783-ee6b-4e33-bb44-13090ecefb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an AI assistant with a witty sense of humor and a knack for crafting clever puns and wordplay. \n",
    "When a user provides a topic, your task is to generate a list of puns, play on words, or humorous phrases related to that topic. \n",
    "The wordplay should be original, creative, and aim to elicit a laugh or a groan from the reader.\"\n",
    "\"\"\"\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "\n",
    "human_prompt = [\n",
    "            {   \n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"{question}\"\n",
    "            },\n",
    "        ]\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message_template,\n",
    "        human_message_template\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab7fd2e2-8e0f-4e6f-bed6-a184398ffbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse_context, observe\n",
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse()\n",
    "\n",
    "@observe()\n",
    "def call_llm(prompt):\n",
    "    langfuse_handler = langfuse_context.get_current_langchain_handler()\n",
    "    for chunk in chain.stream({\"question\": prompt}, config={\"callbacks\":[langfuse_handler]}):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    return langfuse_handler\n",
    "\n",
    "def user_feedback(trace_id, value, comment):\n",
    "    trace = langfuse.score(\n",
    "        trace_id=trace_id,\n",
    "        name=\"user_feedback\",\n",
    "        value=value,\n",
    "        comment=comment\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "305577a5-01be-4899-8f8d-599f908bea96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackiexc/GitHub/LLM_Cookbooks/venv/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, here are some fishing-themed puns and wordplay for you:\n",
      "\n",
      "1. \"Reel-y glad you asked about fishing puns!\"\n",
      "2. \"I'm hooked on coming up with these!\"\n",
      "3. \"Bait-er believe I've got more where that came from.\"\n",
      "4. \"These puns are a little fishy, but I hope they still catch your interest.\"\n",
      "5. \"I'm casting my line and hoping these puns make you chuckle.\"\n",
      "6. \"Let's see if I can net you a laugh with these fishing jokes.\"\n",
      "7. \"I'm reeling in the best puns I can for this aquatic topic.\"\n",
      "8. \"These puns may be a little on the scale-y side, but they're meant in good fin!\"\n",
      "9. \"I'm hoping these puns will have you saying 'that's a-mazing!'\"\n",
      "10. \"I'm just trying to reel you in with my clever fishing wit.\"\n",
      "\n",
      "How's that? I tried to cover a range of puns and wordplay related to fishing, from fishing gear to fish puns. Let me know if you'd like me to try a different topic!"
     ]
    }
   ],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "first_call_trace_id = call_llm(\"Fishing\").get_trace_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14b1d50b-08e6-4a38-9de7-c82b94266467",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feedback(first_call_trace_id, 1, \"super fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a23f86-ec90-426d-86cb-0a0e8ff22c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
