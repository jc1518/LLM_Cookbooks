{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4f2a64-2294-4b58-8089-366566976162",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a26672c7-90c1-4eca-900e-e7c16f19dda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Anthropic API Key: ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Anthropic API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa76c14-3b34-45c3-ad9b-6e33f87f510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f9f4bd2-a172-4582-aa78-0ac3ccf77f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm afraid I don't have enough information to make a direct comparison between myself and GPT-4. GPT-4 is a very capable model created by OpenAI, but the details of its capabilities compared to mine are not something I'm fully aware of. I was created and trained by Anthropic using different approaches than GPT models. Rather than speculating, I would encourage you to try out both AI assistants and form your own assessment based on your experience with each of us. I aim to be helpful in my own right without making claims about superiority over other AI systems.\", response_metadata={'id': 'msg_01GDM9zubAni3Z11KvQ6LwFe', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 18, 'output_tokens': 126}}, id='run-7aced3e2-5ed6-4fed-a037-232fec1d77c4-0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Is Claude 3 better than GPT4?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0c38f6-a1c6-4b81-98f2-f8905e531ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "tools = [TavilySearchResults(max_results=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4054beb-8573-4dcc-9a6e-86a9893af38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are helpful assistant. Make sure to use tavily_search_results_json tool for information.\"\n",
    "        ),\n",
    "        (\n",
    "            \"placeholder\", \"{chat_history}\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\", \"{input}\"\n",
    "        ),\n",
    "        (\n",
    "            \"placeholder\", \"{agent_scratchpad}\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3796c47e-f325-487d-97a6-4a68881c03ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackiexc/GitHub/LLM_Cookbooks/venv/lib/python3.11/site-packages/langchain_anthropic/chat_models.py:347: UserWarning: stream: Tool use is not yet supported in streaming mode.\n",
      "  warnings.warn(\"stream: Tool use is not yet supported in streaming mode.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'langchain tool calling agent'}`\n",
      "responded: [{'id': 'toolu_014bsGxCuckPtPKAbZkhZZCK', 'input': {'query': 'langchain tool calling agent'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://python.langchain.com/docs/use_cases/tool_use/', 'content': 'A large collection of built-in Tools. Provides a lot of flexibility in how you call these tools. There are two main ways to use tools: chains and agents. Chains lets you create a pre-defined sequence of tool usage(s). Agents let the model use tools in a loop, so that it can decide how many times to use tools.'}]\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackiexc/GitHub/LLM_Cookbooks/venv/lib/python3.11/site-packages/langchain_anthropic/chat_models.py:347: UserWarning: stream: Tool use is not yet supported in streaming mode.\n",
      "  warnings.warn(\"stream: Tool use is not yet supported in streaming mode.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mLangChain's tool calling agent refers to a type of agent in LangChain that can interact with and call various tools during its execution. An agent consists of a language model and a set of allowed tools it can utilize.\n",
      "\n",
      "The key aspects are:\n",
      "\n",
      "1) The agent has access to a set of predefined tools it can call and execute. Common tools include search engines, databases, APIs etc.\n",
      "\n",
      "2) The language model powering the agent can analyze the given inputs and determine which tool(s) to use and in what order.\n",
      "\n",
      "3) The agent wraps the language model in a loop, allowing it to call multiple tools in sequence as needed to accomplish the task.\n",
      "\n",
      "4) This enables more capable and open-ended task completion by leveraging both the language model's reasoning abilities and access to external tools/data sources.\n",
      "\n",
      "So in summary, the tool calling agent provides a way for language models to not just rely on their internal knowledge, but to bring in external tool capabilities as well in a flexible manner.\n",
      "\n",
      "However, models can also call tools directly without being wrapped in an agent architecture. This allows chaining/sequencing of tool calls in a predefined order rather than the more flexible agent approach. The appropriate approach depends on the specific use case requirements.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is Langchain tool calling agent? Can model just call tools without running as an agent?',\n",
       " 'output': \"LangChain's tool calling agent refers to a type of agent in LangChain that can interact with and call various tools during its execution. An agent consists of a language model and a set of allowed tools it can utilize.\\n\\nThe key aspects are:\\n\\n1) The agent has access to a set of predefined tools it can call and execute. Common tools include search engines, databases, APIs etc.\\n\\n2) The language model powering the agent can analyze the given inputs and determine which tool(s) to use and in what order.\\n\\n3) The agent wraps the language model in a loop, allowing it to call multiple tools in sequence as needed to accomplish the task.\\n\\n4) This enables more capable and open-ended task completion by leveraging both the language model's reasoning abilities and access to external tools/data sources.\\n\\nSo in summary, the tool calling agent provides a way for language models to not just rely on their internal knowledge, but to bring in external tool capabilities as well in a flexible manner.\\n\\nHowever, models can also call tools directly without being wrapped in an agent architecture. This allows chaining/sequencing of tool calls in a predefined order rather than the more flexible agent approach. The appropriate approach depends on the specific use case requirements.\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What is Langchain tool calling agent? Can model just call tools without running as an agent?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc0f97d2-4096-472b-8a3f-130ffc0f74be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackiexc/GitHub/LLM_Cookbooks/venv/lib/python3.11/site-packages/langchain_anthropic/chat_models.py:347: UserWarning: stream: Tool use is not yet supported in streaming mode.\n",
      "  warnings.warn(\"stream: Tool use is not yet supported in streaming mode.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI'm afraid I don't actually have any information about what you had for lunch today, since you said you skipped it. As an AI assistant without access to details about your personal life, I can only respond based on the information provided to me directly. Unless you provide more context about having eaten lunch, I have to assume you did not have anything since you stated you skipped it.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What did I have for lunch? Don't use tools to look this up unless you NEED to\",\n",
       " 'chat_history': [HumanMessage(content='Hey, I skipped my lunch Today'),\n",
       "  AIMessage(content='Are you hungry now?')],\n",
       " 'output': \"I'm afraid I don't actually have any information about what you had for lunch today, since you said you skipped it. As an AI assistant without access to details about your personal life, I can only respond based on the information provided to me directly. Unless you provide more context about having eaten lunch, I have to assume you did not have anything since you stated you skipped it.\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What did I have for lunch? Don't use tools to look this up unless you NEED to\",\n",
    "        \"chat_history\":[\n",
    "            HumanMessage(content=\"Hey, I skipped my lunch Today\"),\n",
    "            AIMessage(content=\"Are you hungry now?\")\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c68ce2-bffc-46ca-a76f-46bfea85eb55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
